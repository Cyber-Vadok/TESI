{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labeled_df = pd.read_csv('EIF_labeled.csv')\n",
    "labeled_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labeled_df = labeled_df.drop(columns='Unnamed: 0')\n",
    "labeled_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.341-b10, mixed mode)\n",
      "  Starting server from C:\\Users\\Robivad\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\Robivad\\AppData\\Local\\Temp\\tmpy08ezdn_\n",
      "  JVM stdout: C:\\Users\\Robivad\\AppData\\Local\\Temp\\tmpy08ezdn_\\h2o_Robivad_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\Robivad\\AppData\\Local\\Temp\\tmpy08ezdn_\\h2o_Robivad_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/plain": "--------------------------  ------------------------------\nH2O_cluster_uptime:         03 secs\nH2O_cluster_timezone:       Europe/Berlin\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.36.1.4\nH2O_cluster_version_age:    1 month and 11 days\nH2O_cluster_name:           H2O_from_python_Robivad_c483f2\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    2.646 Gb\nH2O_cluster_total_cores:    4\nH2O_cluster_allowed_cores:  4\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.10.6 final\n--------------------------  ------------------------------",
      "text/html": "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n<td>03 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Europe/Berlin</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.36.1.4</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>1 month and 11 days </td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_Robivad_c483f2</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>2.646 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.10.6 final</td></tr></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "extendedisolationforest Model Build progress: |██████████████████████████████████| (done) 100%\n",
      "extendedisolationforest prediction progress: |███████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2OExtendedIsolationForestEstimator\n",
    "h2o.init()\n",
    "h2o_df = h2o.import_file(\"EIF_labeled.csv\")\n",
    "predictors=['country','amount','userAgent_isPc','userAgent_browserFamily','userAgent_osFamily','IBAN_countryCode','IBAN_bankCode','SIA','CAP','SAE','RAE','companyType']\n",
    "eif = H2OExtendedIsolationForestEstimator()\n",
    "eif.train(x = predictors,training_frame = h2o_df)\n",
    "eif_result = eif.predict(h2o_df)\n",
    "anomaly_score = eif_result[\"anomaly_score\"]\n",
    "mean_length = eif_result[\"mean_length\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "h2o.frame.H2OFrame"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(anomaly_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder_dict=pickle.load(open('enc_dict.pkl','rb'))\n",
    "columns_to_label = ['country', 'userAgent_browserFamily', 'userAgent_osFamily', 'IBAN_countryCode', 'IBAN_bankCode','CAP', 'SIA', 'SAE', 'RAE','companyType']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def inverse_and_scores(if_df,labeled_df,enc_dict,columns,if_model):\n",
    "    df_copy=labeled_df.copy()\n",
    "    scores=if_model.decision_function(if_df)\n",
    "    anomaly_score=if_model.predict(if_df)\n",
    "\n",
    "    for clmn in columns:\n",
    "        df_copy[clmn]=enc_dict[clmn].inverse_transform(df_copy[clmn])\n",
    "\n",
    "    df_copy['scores'] = scores\n",
    "    df_copy['anomaly_score'] = anomaly_score\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "df_scores=inverse_and_scores(X,labeled_df,encoder_dict,columns_to_label,model)\n",
    "\n",
    "df_scores.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}